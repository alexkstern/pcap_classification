{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f46ad4d-5ea3-4c88-8a69-4e6c80ff1653",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e42b27-d5e3-47c2-9137-45779900cdbd",
   "metadata": {},
   "source": [
    "## Setting up datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae45aa-abc7-48dc-9f39-b3a771c541b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#Put the path to the directories that contain your processed data. \n",
    "#The directory should be split into high and low priority\n",
    "dirs = [\n",
    "    \"sensor_pcap_classification/Data/Processed/BackdoorSensor\",\n",
    "    \"sensor_pcap_classification/Data/Processed/CO2Sensor\",\n",
    "    \"sensor_pcap_classification/Data/Processed/NoiseSensor\",\n",
    "    \"sensor_pcap_classification/Data/Processed/TempHumiditySensor\",\n",
    "    \"sensor_pcap_classification/Data/Processed/VibrationSensor\"]\n",
    "\n",
    "image_files = []\n",
    "classifications = []\n",
    "sensor_types = []\n",
    "\n",
    "# Iterate over the files in the additional directories\n",
    "for dir in dirs:\n",
    "    sensor_type = os.path.basename(dir)  # Extract the sensor type from the directory path\n",
    "    high_priority_dir = os.path.join(dir, \"high_pr\")\n",
    "    for file_name in os.listdir(high_priority_dir):\n",
    "        file_path = os.path.join(high_priority_dir, file_name)\n",
    "        image_files.append(file_path)\n",
    "        classifications.append(\"high\")\n",
    "        sensor_types.append(sensor_type)\n",
    "\n",
    "    low_priority_dir = os.path.join(dir, \"low_pr\")\n",
    "    for file_name in os.listdir(low_priority_dir):\n",
    "        file_path = os.path.join(low_priority_dir, file_name)\n",
    "        image_files.append(file_path)\n",
    "        classifications.append(\"low\")\n",
    "        sensor_types.append(sensor_type)\n",
    "\n",
    "# Create the DataFrame\n",
    "image_dataset = pd.DataFrame({\n",
    "    \"Image File\": image_files,\n",
    "    \"Classification\": classifications,\n",
    "    \"Sensor Type\": sensor_types  # Add the Sensor Type column\n",
    "})\n",
    "\n",
    "image_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c829f7-cf57-47bc-92b0-826de22e2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"sensor_pcap_classification/Classification_model/image_dataset_all.csv\"\n",
    "image_dataset.to_csv(csv_file_path)\n",
    "image_dataset_all= pd.read_csv(csv_file_path, index_col=0)\n",
    "image_dataset_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0f58dc-c7be-4e75-8aa2-e0221f3907b3",
   "metadata": {},
   "source": [
    "A few trials were done, results found that the whole dataset wasn't needed for good results. Hence, we are taking a sample of the larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e676f-6d79-4116-9e1c-b9105fe09983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Group the image_dataset by \"Sensor Type\" and \"Classification\"\n",
    "grouped = image_dataset.groupby([\"Sensor Type\", \"Classification\"])\n",
    "\n",
    "# Function to sample 500 rows from each group\n",
    "def sample_rows(group):\n",
    "    return group.sample(n=500, random_state=42)\n",
    "\n",
    "# Sample 500 rows from each group and concatenate into one DataFrame\n",
    "sampled_dataset = pd.concat([sample_rows(group) for _, group in grouped])\n",
    "\n",
    "# Reset the index of the new DataFrame\n",
    "sampled_dataset = sampled_dataset.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782488d8-1deb-486e-9706-2494c6d4f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"sensor_pcap_classification/Classification_model/image_dataset_training.csv\"\n",
    "sampled_dataset.to_csv(csv_file_path)\n",
    "image_dataset= pd.read_csv(csv_file_path, index_col=0)\n",
    "image_dataset=image_dataset.reset_index(drop=True)\n",
    "image_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed7f0f-c1b3-4bff-a410-b58ddb9093d7",
   "metadata": {},
   "source": [
    "## Data preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0cecec-c921-4f1c-83ff-cdcd8ebc3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c08d1-735d-4418-8a04-c3469f544784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from timm import create_model\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transform for preprocessing the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load your dataset CSV file\n",
    "df = image_dataset\n",
    "\n",
    "# Separate high and low classified images\n",
    "high_classified = df[df[\"Classification\"] == \"high\"]\n",
    "low_classified = df[df[\"Classification\"] == \"low\"]\n",
    "\n",
    "# Split high and low classified images into train, validation, and test sets while maintaining the same ratio\n",
    "train_high, valtest_high = train_test_split(high_classified, test_size=0.2, random_state=42, stratify=high_classified[\"Sensor Type\"])\n",
    "val_high, test_high = train_test_split(valtest_high, test_size=0.5, random_state=42, stratify=valtest_high[\"Sensor Type\"])\n",
    "\n",
    "train_low, valtest_low = train_test_split(low_classified, test_size=0.2, random_state=42, stratify=low_classified[\"Sensor Type\"])\n",
    "val_low, test_low = train_test_split(valtest_low, test_size=0.5, random_state=42, stratify=valtest_low[\"Sensor Type\"])\n",
    "\n",
    "# Concatenate high and low classified images for each dataset\n",
    "train_df = pd.concat([train_high, train_low], ignore_index=True)\n",
    "val_df = pd.concat([val_high, val_low], ignore_index=True)\n",
    "test_df = pd.concat([test_high, test_low], ignore_index=True)\n",
    "\n",
    "# Define the custom dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.data.iloc[index][\"Image File\"]\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.data.iloc[index][\"Classification\"]\n",
    "        label = 1 if label == \"high\" else 0\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Create custom datasets for training, validation, and test\n",
    "train_dataset = CustomDataset(train_df, transform=transform)\n",
    "val_dataset = CustomDataset(val_df, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ebd47a-058f-4929-b15f-477b285b89f6",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb5a7c-4c3f-40ba-b502-fd2495a23e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "model_name = \"resnet18\"  # Replace with the desired model architecture\n",
    "num_classes = 2\n",
    "model = create_model(model_name, pretrained=True, num_classes=num_classes).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update()\n",
    "\n",
    "    # Calculate average train loss\n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "\n",
    "    # Evaluation on the validation set\n",
    "    model.eval()\n",
    "    val_accuracy = 0.0\n",
    "    val_predictions = []\n",
    "    val_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            val_accuracy += accuracy_score(predicted.cpu(), labels.cpu()) * images.size(0)\n",
    "            val_predictions.extend(predicted.cpu().numpy())\n",
    "            val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate average validation accuracy\n",
    "    val_accuracy = val_accuracy / len(val_dataset)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    val_f1 = f1_score(val_targets, val_predictions)\n",
    "\n",
    "    # Print training progress\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f} - Val Accuracy: {val_accuracy:.4f} - Val F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "    # Save the model with the best validation accuracy\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), \"sensor_pcap_classification/Classification_model/main_pcap_classification_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41787e75-da22-4249-9efe-961363cd0cff",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20461ac-f51f-41d2-87fa-501e093bcb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the original checkpoint file\n",
    "model = create_model(model_name, pretrained=False, num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"sensor_pcap_classification/Classification_model/main_pcap_classification_model.pth\"))\n",
    "# Evaluation on the validation set\n",
    "model.eval()\n",
    "val_predictions = []\n",
    "val_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        val_predictions.extend(predicted.cpu().numpy())\n",
    "        val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate validation accuracy\n",
    "val_accuracy = accuracy_score(val_targets, val_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "val_f1 = f1_score(val_targets, val_predictions)\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "confusion = confusion_matrix(val_targets, val_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Validation F1 Score:\", val_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87376f49-82c9-4ec9-bc65-1ed8c4000d5b",
   "metadata": {},
   "source": [
    "## Time for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e879f5-c61a-4568-bdb2-026c77a08bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from timm import create_model\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix  # Add these import statements\n",
    "\n",
    "# Define the model architecture and number of classes\n",
    "model_name = 'resnet18'\n",
    "num_classes = 2\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model from the original checkpoint file\n",
    "model = create_model(model_name, pretrained=False, num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"sensor_pcap_classification/Classification_model/main_pcap_classification_model.pth\"))\n",
    "\n",
    "# Evaluation on the validation set\n",
    "model.eval()\n",
    "val_predictions = []\n",
    "val_targets = []\n",
    "total_inference_time = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        start_time = time.time()  # Start timing the inference\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        end_time = time.time()  # End timing the inference\n",
    "\n",
    "        total_inference_time += (end_time - start_time)\n",
    "\n",
    "        val_predictions.extend(predicted.cpu().numpy())\n",
    "        val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate validation accuracy\n",
    "val_accuracy = accuracy_score(val_targets, val_predictions)\n",
    "\n",
    "# Calculate F1 score\n",
    "val_f1 = f1_score(val_targets, val_predictions)\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "confusion = confusion_matrix(val_targets, val_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Validation F1 Score:\", val_f1)\n",
    "\n",
    "# Calculate average inference time per pcap\n",
    "num_pcaps = len(val_loader.dataset)  # Number of samples (pcaps) in the validation set\n",
    "average_inference_time_per_pcap = total_inference_time / num_pcaps\n",
    "print(\"Average Inference Time per PCAP:\", average_inference_time_per_pcap, \"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
